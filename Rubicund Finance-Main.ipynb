{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import *\n",
    "import dask.dataframe as dd\n",
    "import pytz\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows',9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediroutes data uploaded!!\n"
     ]
    }
   ],
   "source": [
    "###  UPLOAD MEDIROUTES DATA - format in csv\n",
    "\n",
    "#up load all files containing Mediroutes data\n",
    "dt = dd.read_csv('C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\data science\\\\Rubicund Finance\\\\Mediroutes\\\\Mediroutes*.csv',dtype={'DL Number': 'float64','Vehicle': 'float64','Paid': 'float64','Distance Difference': 'float64','Notification Status': 'object','Patient Address': 'object','Dropoff Zip':'int64','Pickup Zip':'int64'}).compute()\n",
    "\n",
    "# Rename and keep only the important columns\n",
    "dt = dt.rename(columns={'Patient':'Name','Charge':'Cost','Import Distance':'Miles'})\n",
    "\n",
    "#Assign Trip Legs to the trips\n",
    "dt['Leg'] = 'A'\n",
    "\n",
    "# Assign 'A' to the 'Duplicate' column for non-duplicate rows\n",
    "dt.loc[~dt.duplicated(['Name','Date']), 'Leg'] = 'A'\n",
    "\n",
    "# Assign 'B' to the 'Duplicate' column for duplicate rows\n",
    "dt.loc[dt.duplicated(['Name','Date'],'first'), 'Leg'] = 'B'\n",
    "\n",
    "print('Mediroutes data uploaded!!')\n",
    "\n",
    "dt.to_csv('C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\Rubicund Data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alivi EOPS uploaded!!\n"
     ]
    }
   ],
   "source": [
    "#### UPLOAD ALL ALIVI EOP'S - format in Excel .xlsx\n",
    "\n",
    "# List all the Excel files in the folder\n",
    "folder = 'C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\data science\\\\Rubicund Finance\\\\Alivi'\n",
    "filenames = os.listdir(folder)\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through the files\n",
    "for file in filenames:\n",
    "    # Check if the file is an Excel file\n",
    "    if file.endswith('.xlsx'):\n",
    "        # Read the Excel file and skip the first 2 rows\n",
    "        df = pd.read_excel((os.path.join(folder, file)),skiprows=[0, 1])\n",
    "        # Add the DataFrame to the list\n",
    "        df_list.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "alv_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Convert time column to string\n",
    "alv_all['Scheduled Time'] = alv_all['Scheduled Time'].astype(str)\n",
    "\n",
    "# Split the date time format to show only the date\n",
    "alv_all['Date'] = alv_all['Scheduled Time'].apply(lambda x : x.split(' ')[0])\n",
    "\n",
    "# Filter only needed columns, drop na and sort by date and name and reset index\n",
    "alv_all = alv_all.loc[:,['Reference Number','Date','Member Name','Miles','Cost']].dropna().sort_values(['Date','Member Name'],ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Assign Trip Legs to the trips\n",
    "alv_all['Leg'] = 'A'\n",
    "\n",
    "# Assign 'A' to the 'Duplicate' column for non-duplicate rows\n",
    "alv_all.loc[~alv_all.duplicated(['Member Name','Date']), 'Leg'] = 'A'\n",
    "\n",
    "# Assign 'B' to the 'Duplicate' column for duplicate rows\n",
    "alv_all.loc[alv_all.duplicated(['Member Name','Date'],'first'), 'Leg'] = 'B'\n",
    "\n",
    "\n",
    "# Format the Name column\n",
    "alv_all['First Name'] = alv_all['Member Name'].apply(lambda x : x.split(' ')[0])\n",
    "alv_all['Last Name'] = alv_all['Member Name'].apply(lambda x : x.split(' ')[-1])\n",
    "\n",
    "# Concatenate the 'First Name' and 'Last Name' columns with a comma in between\n",
    "alv_all['Name'] = alv_all['First Name'] + ', ' + alv_all['Last Name']\n",
    "\n",
    "# Drop the 'First Name' and 'Last Name' columns\n",
    "alv_all = alv_all.drop(columns=['First Name', 'Last Name','Member Name'])\n",
    "\n",
    "# Re arrange columns\n",
    "alv_all = alv_all.loc[:,['Date','Name','Cost','Leg']]\n",
    "alv_all['Trip'] = alv_all['Date'] + ' ' + alv_all['Name'] + ' ' + alv_all['Leg']\n",
    "\n",
    "print('Alivi EOPS uploaded!!')\n",
    "#alv_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modivcare EOPS uploaded!!\n"
     ]
    }
   ],
   "source": [
    "### Upload Modivcare EOPS\n",
    "\n",
    "df = dd.read_csv('C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\data science\\\\Rubicund Finance\\\\Modivcare\\\\LGTC*.csv',dtype={'Cancellation Reason': 'object','Manually Denied Comment': 'object','Manually Denied Reason': 'object','Manually Denied Trip ID': 'object'}).compute()\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Filter only needed columns\n",
    "df = df.loc[:,['Trip ID','Trip Leg','Trip Leg Date','Rider','LCI Miles','Amount','Invoice Number','Batch','Record Type','Denial Note','Manually Denied Comment']]\n",
    "#df = df.loc[:,['Trip ID','Trip Leg','Trip Leg Date','Rider','LCI Miles','Amount']]\n",
    "\n",
    "# Rename columns\n",
    "mod_all = df.rename(columns={'Trip Leg':'Leg','Trip Leg Date':'Date','Rider':'Name','LCI Miles':'Miles','Amount':'Cost'})\n",
    "\n",
    "\n",
    "# Define a function to remove the dollar sign from cost column\n",
    "def remove_dollar_sign(s):\n",
    "    return s.replace('$','')\n",
    "\n",
    "# Apply the function to the 'amount' column\n",
    "mod_all['Cost'] = mod_all['Cost'].apply(remove_dollar_sign)\n",
    "\n",
    "# Change cost column to float\n",
    "mod_all['Cost'] = mod_all['Cost'].astype(float)\n",
    "\n",
    "\n",
    "# Sort data\n",
    "mod_all.dropna().sort_values(['Date','Name'],ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Combine Date, Trip ID and Leg to form Authorization column\n",
    "mod_all['Date'] = pd.to_datetime(mod_all['Date'], format='%m/%d/%y')\n",
    "mod_all['Date'] = mod_all['Date'].dt.strftime('%Y/%m/%d') #Show the year column in yyyy format\n",
    "\n",
    "mod_all['date_temp'] = mod_all['Date'].str.replace(r'\\D', '')\n",
    "mod_all['Trip ID'] = mod_all['Trip ID'].astype(str)\n",
    "\n",
    "mod_all['Authorization'] = '1-' + mod_all['date_temp'] + '-' + mod_all['Trip ID'] + '-' + mod_all['Leg']\n",
    "mod_all = mod_all.drop('date_temp', axis=1)\n",
    "\n",
    "\n",
    "# Get all the rows that contain verified paid**  under the record type column  \n",
    "mod_all = mod_all.loc[mod_all['Record Type'].str.contains('Verified-Paid')]    \n",
    "\n",
    "# Get only the authorization column\n",
    "mod_all = mod_all.loc[:,['Authorization']]\n",
    "\n",
    "\n",
    "#mod_all.to_csv('C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\data science\\\\Rubicund Finance\\\\Modivcare checks.csv',index=False)\n",
    "\n",
    "print('Modivcare EOPS uploaded!!')\n",
    "#mod_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check Alivi Invoices\n",
    "\n",
    "# Filter Alivi trips\n",
    "alv = dt[dt['Funding Source'] == 'Alivi']\n",
    "alv = alv.loc[:,['Date','Name','Cost']]\n",
    "\n",
    "\n",
    "#Assign Trip Legs to the trips\n",
    "alv['Leg'] = 'A'\n",
    "\n",
    "# Assign 'A' to the 'Duplicate' column for non-duplicate rows\n",
    "alv.loc[~alv.duplicated(['Name','Date']), 'Leg'] = 'A'\n",
    "\n",
    "# Assign 'B' to the 'Duplicate' column for duplicate rows\n",
    "alv.loc[alv.duplicated(['Name','Date'],'first'), 'Leg'] = 'B'\n",
    "\n",
    "alv['Trip'] = alv['Date'] + ' ' + alv['Name'] + ' ' + alv['Leg']\n",
    "\n",
    "#print(alv_all['Name']=='WILLIAMS RICHARD')\n",
    "\n",
    "\n",
    "# Get payments not found on EOP\n",
    "#alivi = pd.merge(alv_all,alv, how='inner').drop_duplicates('Reference Number')\n",
    "#alivi = alivi.loc[:,['Reference Number','Date','Leg','Name','Miles','Cost']]\n",
    "\n",
    "\n",
    "alivi = pd.merge(alv_all,alv, how='outer', indicator=True)\n",
    "alivi = alivi[alivi['_merge']=='right_only']\n",
    "#alivi = alivi.drop('_merge',axis=1)\n",
    "\n",
    "# Get payments not found on EOP \n",
    "#modiv = pd.merge(mod_all,mod, on='Authorization', how='outer', indicator=True)\n",
    "#modiv = modiv[modiv['_merge']=='right_only']\n",
    "#modiv = modiv.drop('_merge', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show sum of unpaid invoices and details\n",
    "#print('Total Alivi Unpaid Invoice = ', alivi['Cost'].sum())\n",
    "\n",
    "#alivi.to_csv('C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\data science\\\\Rubicund Finance\\\\Alivi Pending Invoices.csv',index=False)\n",
    "\n",
    "#alivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Modivcare Unpaid Invoice =  204284.29\n"
     ]
    }
   ],
   "source": [
    "#### Check Modivcare data from Mediroutes\n",
    "\n",
    "# Filter Alivi trips\n",
    "mod = dt[dt['Funding Source'] == 'Modivcare']\n",
    "mod = mod.loc[:,['Date','Name','Cost','Authorization']]\n",
    "\n",
    "#modiv = mod[mod['Authorization'].isin(mod_all['Authorization'])]\n",
    "\n",
    "# Get payments not found on EOP \n",
    "modiv = pd.merge(mod_all,mod, on='Authorization', how='outer', indicator=True)\n",
    "modiv = modiv[modiv['_merge']=='right_only']\n",
    "modiv = modiv.drop('_merge', axis=1)\n",
    "\n",
    "\n",
    "# Show sum of unpaid invoices and details\n",
    "print('Total Modivcare Unpaid Invoice = ', modiv['Cost'].sum())\n",
    "\n",
    "#modiv.to_csv('C:\\\\Users\\\\vjron\\\\OneDrive\\\\Desktop\\\\data science\\\\Rubicund Finance\\\\Modivcare Pending Invoices.csv',index=False)\n",
    "\n",
    "#modiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time frame  2024-03-10 to 2024-03-23\n",
      "Total pay =  4674.28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Driver</th>\n",
       "      <th>Days worked</th>\n",
       "      <th>rate</th>\n",
       "      <th>Net Pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cedric</td>\n",
       "      <td>01/18/2023</td>\n",
       "      <td>Cedric</td>\n",
       "      <td>9</td>\n",
       "      <td>160</td>\n",
       "      <td>1440.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPE</td>\n",
       "      <td>10/28/2023</td>\n",
       "      <td>Opeoluwa Caston</td>\n",
       "      <td>1</td>\n",
       "      <td>154.28</td>\n",
       "      <td>154.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WALE</td>\n",
       "      <td>12/13/2023</td>\n",
       "      <td>Wale</td>\n",
       "      <td>8</td>\n",
       "      <td>160</td>\n",
       "      <td>1280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yousuf</td>\n",
       "      <td>07/24/2023</td>\n",
       "      <td>Amir Synders</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>1800.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Run  Start Date           Driver  Days worked    rate  Net Pay\n",
       "0  Cedric  01/18/2023           Cedric            9     160  1440.00\n",
       "1     OPE  10/28/2023  Opeoluwa Caston            1  154.28   154.28\n",
       "2    WALE  12/13/2023             Wale            8     160  1280.00\n",
       "3  Yousuf  07/24/2023     Amir Synders           10     180  1800.00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect() # Clear memory\n",
    "\n",
    "#### Drivers Pay\n",
    "# Create a NumPy array containing Runs and Daily rates\n",
    "rate = np.array([['Beulah',154.28, 'Beulah Minter', '10/28/2022'], \n",
    "                 ['Erica',160, 'Erica Williams', '08/04/2022'],\n",
    "                 ['Cedric',160, 'Cedric', '01/18/2023'],\n",
    "                 ['BENEDICT',150.28, 'Benedict Kamara', '01/10/2023'],\n",
    "                 ['Valeria',154.28, 'Valeria DeOliveria', '11/05/2022'],\n",
    "                 ['Jenell',154.28, 'Jenell Jones Johnson', '12/13/2022'],\n",
    "                 ['BAYO',154.28, 'Adebayo Olasupo', '12/13/2022'],\n",
    "                 ['FRED',154.28, 'Fredison Kpogban', '04/17/2023'],\n",
    "                 ['Anthony',154.28, 'Anthony Sseremba', '05/05/2023'],\n",
    "                 ['Jamil',154.28, 'Jamil Adebello', '08/13/2023'],\n",
    "                 ['SAMARIA',154.28, 'Brittani Castle', '08/21/2023'],\n",
    "                 ['OPE',154.28, 'Opeoluwa Caston', '10/28/2023'],\n",
    "                 ['BONA',154.28, 'Bona Abraham', '12/13/2023'],\n",
    "                 ['WALE',160, 'Wale', '12/13/2023'],\n",
    "                 ['Yousuf',180, 'Amir Synders', '07/24/2023']])\n",
    "\n",
    "rates = pd.DataFrame(rate, columns=['Run', 'rate','Driver','Start Date'])     # Create a DataFrame from the array\n",
    "rates['rate'].astype(float)\n",
    "\n",
    "\n",
    "# Get data from Mediroutes and clean the data\n",
    "run = dt.loc[:,['Date','Run']]\n",
    "run['Date'] = pd.to_datetime(run['Date'])\n",
    "\n",
    "# Select the date you want to process\n",
    "date_from = '2024-03-10'   #yyyy-mm-dd\n",
    "date_to = '2024-03-23'\n",
    "check_date = '29-03-2024'  #mm-dd-yyyy\n",
    "\n",
    "#date_from = '2023-06-04'   #yyyy-mm-dd\n",
    "#date_to = '2023-06-17'\n",
    "#check_date = '03-03-2023'  #mm-dd-yyyy\n",
    "\n",
    "run = run.loc[run['Date'].between(date_from, date_to)].sort_values('Run', ascending=True).drop_duplicates()\n",
    "\n",
    "#Get the number of days worked per run \n",
    "run1 = run.groupby(['Run']).count()   # number of days worked\n",
    "\n",
    "\n",
    "# Merge the run and daily rates data\n",
    "run_test = pd.merge(run1,rates, on='Run', how='inner').drop_duplicates()\n",
    "\n",
    "run_test['Net Pay'] = run_test['Date']*run_test['rate'].astype(float)\n",
    "run_test['Net Pay'] = run_test['Net Pay'].round(2)\n",
    "\n",
    "\n",
    "run_test = run_test.rename(columns={'Date':'Days worked'})\n",
    "run_test = run_test.loc[:,['Run','Start Date','Driver','Days worked','rate','Net Pay']]\n",
    "\n",
    "print('Time frame ', date_from, 'to', date_to)\n",
    "print('Total pay = ', run_test['Net Pay'].sum())\n",
    "run_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              EXPLANATION OF PAYMENT                             \n",
      "\n",
      "\n",
      "Duration: 2024-03-10 - 2024-03-23\n",
      "\n",
      "CONTRACTOR NAME:  Wale\n",
      "SSN: XXX-XX-XXXX\n",
      "SERVICE PROVIDED: NEMT DRIVER SERVICES\n",
      "\n",
      "DEDUCTIONS\n",
      "GL: $9.72\n",
      "Tax withheld: $0.00\n",
      "\n",
      "\n",
      "DAILY EARNINGS\n",
      "Rate: $120.00\n",
      "Gas: $40.00\n",
      "\n",
      "\n",
      "  Run  Start Date Driver  Days worked rate  Net Pay\n",
      " WALE  12/13/2023   Wale            8  160   1280.0\n",
      "\n",
      "Check date:  29-03-2024\n",
      "\n",
      "schedule grid\n",
      "Driver       Date rate\n",
      "  Wale 2024-03-11  160\n",
      "  Wale 2024-03-12  160\n",
      "  Wale 2024-03-13  160\n",
      "  Wale 2024-03-18  160\n",
      "  Wale 2024-03-19  160\n",
      "  Wale 2024-03-20  160\n",
      "  Wale 2024-03-21  160\n",
      "  Wale 2024-03-22  160\n"
     ]
    }
   ],
   "source": [
    "driver_name = 'Wale'\n",
    "\n",
    "run_tt = pd.merge(run,rates, on='Run', how='inner').drop_duplicates().sort_values('Date', ascending=True)\n",
    "run_tt = run_tt.loc[:,['Driver','Date','rate']]\n",
    "\n",
    "print('                                              EXPLANATION OF PAYMENT                             ')\n",
    "print('')\n",
    "print('')\n",
    "print('Duration:', date_from, '-', date_to)\n",
    "print()\n",
    "print('CONTRACTOR NAME: ', driver_name)\n",
    "print('SSN: XXX-XX-XXXX')\n",
    "print('SERVICE PROVIDED: NEMT DRIVER SERVICES')\n",
    "print()\n",
    "#print('START DATE: ', run_tt.loc[run_tt['Start Date'] == run_name].to_string(index=False))\n",
    "\n",
    "print('DEDUCTIONS')\n",
    "print('GL: $9.72')\n",
    "print('Tax withheld: $0.00')\n",
    "print()\n",
    "print()\n",
    "print('DAILY EARNINGS')\n",
    "print('Rate: $120.00')\n",
    "print('Gas: $40.00')\n",
    "#print('Toll: $4.00')\n",
    "print()\n",
    "print()\n",
    "print(run_test.loc[run_test['Driver'] == driver_name].to_string(index=False))\n",
    "print()\n",
    "print('Check date: ',check_date)\n",
    "print()\n",
    "print('schedule grid')\n",
    "print(run_tt.loc[run_tt['Driver'] == driver_name].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayo - 2nd, 3rd, - pay = 1079.96\n",
    "# antho - pay = 771.40\n",
    "#   Jamil - 29th pay $77.14; pay = 539.98\n",
    "# Jenell - 29th pay $0 ; pay = 1079.96\n",
    "#total = 3471.30\n",
    "\n",
    "#bayo - $694.26 - half day on 23rd oct \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
